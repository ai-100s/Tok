# 远程转录模型集成设计

## 概述

本文档详细设计了在 Tok 现有 WhisperKit 本地转录架构基础上，集成远程转录模型（如 OpenAI Whisper API、Groq、AssemblyAI 等）的技术方案。设计遵循现有的架构模式，确保向后兼容性和统一的用户体验。

## 设计目标

### 核心目标
1. **向后兼容性**：现有代码无需修改，保持 API 接口稳定
2. **统一体验**：本地和远程转录提供一致的用户界面和交互
3. **智能选择**：根据网络状态、成本、延迟等因素自动选择最佳引擎
4. **渐进式迁移**：可以逐步添加新的转录提供商
5. **配置灵活性**：支持复杂的提供商组合和降级策略

### 非功能性目标
- **性能**：最小化延迟，优化网络调用
- **可靠性**：优雅的错误处理和降级机制
- **安全性**：API 密钥安全存储和传输
- **可扩展性**：易于添加新的转录提供商
- **可观测性**：详细的日志和性能监控

## 现有架构分析

### 当前 TranscriptionClient 架构

```swift
@DependencyClient
struct TranscriptionClient {
  var transcribe: @Sendable (URL, String, DecodingOptions, HexSettings?, @escaping (Progress) -> Void) async throws -> String
  var downloadModel: @Sendable (String, @escaping (Progress) -> Void) async throws -> Void
  var startStreamTranscription: @Sendable (String, DecodingOptions, HexSettings?, @escaping (StreamTranscriptionUpdate) -> Void) async throws -> Void
  // ... 其他方法
}

actor TranscriptionClientLive {
  private var whisperKit: WhisperKit?
  private var currentModelName: String?
  // ... 实现细节
}
```

### 参考架构：AIEnhancementClient

现有的 `AIEnhancementClient` 已经实现了多提供商支持模式：

```swift
enum AIProviderType: String, Codable {
  case ollama = "ollama"      // 本地提供商
  case groq = "groq"          // 远程提供商
}

struct AIEnhancementClient {
  var enhance: @Sendable (String, String, EnhancementOptions, AIProviderType, String?, @escaping (Progress) -> Void) async throws -> String
}
```

## 详细技术设计

### 1. 转录提供商类型定义

```swift
/// 转录提供商类型枚举
enum TranscriptionProviderType: String, Codable, CaseIterable, Equatable {
    case whisperKit = "whisperkit"
    case openai = "openai"
    case groq = "groq"
    case assemblyai = "assemblyai"
    case deepgram = "deepgram"
    
    var displayName: String {
        switch self {
        case .whisperKit:
            return "WhisperKit (本地)"
        case .openai:
            return "OpenAI Whisper API"
        case .groq:
            return "Groq Whisper API"
        case .assemblyai:
            return "AssemblyAI"
        case .deepgram:
            return "Deepgram"
        }
    }
    
    var description: String {
        switch self {
        case .whisperKit:
            return "本地运行，无需网络连接，完全私密"
        case .openai:
            return "OpenAI 官方 Whisper API，高精度识别"
        case .groq:
            return "Groq 提供的超高速 Whisper 推理"
        case .assemblyai:
            return "专业的语音识别 API，支持实时转录"
        case .deepgram:
            return "高性能实时语音识别平台"
        }
    }
    
    var requiresAPIKey: Bool {
        switch self {
        case .whisperKit:
            return false
        case .openai, .groq, .assemblyai, .deepgram:
            return true
        }
    }
    
    var supportsStreaming: Bool {
        switch self {
        case .whisperKit:
            return true
        case .openai:
            return false  // OpenAI Whisper API 目前不支持流式
        case .groq:
            return false  // Groq Whisper 目前不支持流式
        case .assemblyai, .deepgram:
            return true
        }
    }
    
    var supportedLanguages: [String] {
        switch self {
        case .whisperKit:
            return ["auto", "en", "zh", "ja", "ko", "es", "fr", "de", "pt", "ru", "ar"] // WhisperKit 支持的语言
        case .openai, .groq:
            return ["auto"] + WhisperSupportedLanguages.all  // Whisper 模型支持的全部语言
        case .assemblyai:
            return ["en", "es", "fr", "de", "pt", "nl", "it", "pl", "hi", "ja", "zh", "ko"]
        case .deepgram:
            return ["en", "es", "fr", "de", "pt", "ru", "ja", "ko", "zh", "hi", "ar"]
        }
    }
}
```

### 2. 转录引擎协议抽象

```swift
/// 转录引擎协议，定义所有转录引擎必须实现的接口
protocol TranscriptionEngine: Actor {
    /// 引擎类型标识
    var providerType: TranscriptionProviderType { get }
    
    /// 检查引擎是否可用（网络连接、API 密钥等）
    func isAvailable() async -> Bool
    
    /// 获取支持的模型列表
    func getAvailableModels() async throws -> [TranscriptionModel]
    
    /// 预热指定模型（如果需要）
    func prewarmModel(_ modelName: String, progressCallback: @escaping (Progress) -> Void) async throws
    
    /// 批量转录音频文件
    func transcribe(
        audioURL: URL,
        model: String,
        options: DecodingOptions,
        settings: HexSettings?,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String
    
    /// 开始流式转录（如果支持）
    func startStreamTranscription(
        model: String,
        options: DecodingOptions,
        settings: HexSettings?,
        updateCallback: @escaping (StreamTranscriptionUpdate) -> Void
    ) async throws
    
    /// 停止流式转录
    func stopStreamTranscription() async
    
    /// 清理和释放资源
    func cleanup() async
}

/// 转录模型信息
struct TranscriptionModel: Identifiable, Equatable {
    let id: String
    let name: String
    let displayName: String
    let provider: TranscriptionProviderType
    let languages: [String]
    let maxDuration: TimeInterval?  // 最大支持时长（秒）
    let costPerMinute: Double?      // 每分钟成本（美元）
    let avgLatency: TimeInterval?   // 平均延迟（秒）
    let accuracy: Double?           // 准确度评分 0-1
    let isDownloaded: Bool          // 是否已下载到本地
    let requiresInternet: Bool      // 是否需要网络连接
}
```

### 3. 具体引擎实现

#### 本地 WhisperKit 引擎

```swift
/// 本地 WhisperKit 转录引擎（现有实现的封装）
actor LocalTranscriptionEngine: TranscriptionEngine {
    let providerType: TranscriptionProviderType = .whisperKit
    
    // 封装现有的 TranscriptionClientLive 逻辑
    private let whisperKitClient: TranscriptionClientLive
    
    init() {
        self.whisperKitClient = TranscriptionClientLive()
    }
    
    func isAvailable() async -> Bool {
        // 本地引擎始终可用
        return true
    }
    
    func getAvailableModels() async throws -> [TranscriptionModel] {
        let whisperKitModels = try await whisperKitClient.getAvailableModels()
        return whisperKitModels.map { modelName in
            TranscriptionModel(
                id: modelName,
                name: modelName,
                displayName: formatDisplayName(modelName),
                provider: .whisperKit,
                languages: WhisperSupportedLanguages.all,
                maxDuration: nil,  // 无限制
                costPerMinute: 0.0,  // 免费
                avgLatency: getModelLatency(modelName),
                accuracy: getModelAccuracy(modelName),
                isDownloaded: await whisperKitClient.isModelDownloaded(modelName),
                requiresInternet: false
            )
        }
    }
    
    // 其他方法直接委托给 whisperKitClient
    func transcribe(/* ... */) async throws -> String {
        return try await whisperKitClient.transcribe(/* ... */)
    }
    
    // ... 其他实现
}
```

#### OpenAI Whisper API 引擎

```swift
/// OpenAI Whisper API 转录引擎
actor OpenAITranscriptionEngine: TranscriptionEngine {
    let providerType: TranscriptionProviderType = .openai
    
    private let apiKey: String
    private let baseURL = "https://api.openai.com/v1"
    
    init(apiKey: String) {
        self.apiKey = apiKey
    }
    
    func isAvailable() async -> Bool {
        guard !apiKey.isEmpty else { return false }
        
        // 测试 API 连接
        do {
            _ = try await getAvailableModels()
            return true
        } catch {
            return false
        }
    }
    
    func getAvailableModels() async throws -> [TranscriptionModel] {
        // OpenAI Whisper API 支持的模型
        return [
            TranscriptionModel(
                id: "whisper-1",
                name: "whisper-1",
                displayName: "Whisper v1",
                provider: .openai,
                languages: WhisperSupportedLanguages.all,
                maxDuration: 25 * 60,  // 25分钟限制
                costPerMinute: 0.006,   // $0.006/分钟
                avgLatency: 5.0,        // 平均5秒延迟
                accuracy: 0.95,         // 高精度
                isDownloaded: false,
                requiresInternet: true
            )
        ]
    }
    
    func transcribe(
        audioURL: URL,
        model: String,
        options: DecodingOptions,
        settings: HexSettings?,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String {
        let progress = Progress(totalUnitCount: 100)
        progressCallback(progress)
        
        // 准备请求
        var request = URLRequest(url: URL(string: "\(baseURL)/audio/transcriptions")!)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        
        // 创建 multipart 表单数据
        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        var body = Data()
        
        // 添加音频文件
        let audioData = try Data(contentsOf: audioURL)
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"audio.wav\"\r\n".data(using: .utf8)!)
        body.append("Content-Type: audio/wav\r\n\r\n".data(using: .utf8)!)
        body.append(audioData)
        body.append("\r\n".data(using: .utf8)!)
        
        // 添加模型参数
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"model\"\r\n\r\n".data(using: .utf8)!)
        body.append(model.data(using: .utf8)!)
        body.append("\r\n".data(using: .utf8)!)
        
        // 添加语言参数（如果指定）
        if let language = options.language, language != "auto" {
            body.append("--\(boundary)\r\n".data(using: .utf8)!)
            body.append("Content-Disposition: form-data; name=\"language\"\r\n\r\n".data(using: .utf8)!)
            body.append(language.data(using: .utf8)!)
            body.append("\r\n".data(using: .utf8)!)
        }
        
        // 添加响应格式
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"response_format\"\r\n\r\n".data(using: .utf8)!)
        body.append("json".data(using: .utf8)!)
        body.append("\r\n".data(using: .utf8)!)
        
        body.append("--\(boundary)--\r\n".data(using: .utf8)!)
        
        request.httpBody = body
        request.timeoutInterval = 300  // 5分钟超时
        
        progress.completedUnitCount = 20
        progressCallback(progress)
        
        // 发送请求
        let (responseData, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw TranscriptionError.invalidResponse
        }
        
        progress.completedUnitCount = 80
        progressCallback(progress)
        
        if httpResponse.statusCode != 200 {
            let errorMessage = String(data: responseData, encoding: .utf8) ?? "Unknown error"
            throw TranscriptionError.apiError(httpResponse.statusCode, errorMessage)
        }
        
        // 解析响应
        struct OpenAITranscriptionResponse: Codable {
            let text: String
        }
        
        let transcriptionResponse = try JSONDecoder().decode(OpenAITranscriptionResponse.self, from: responseData)
        
        progress.completedUnitCount = 100
        progressCallback(progress)
        
        // 应用后处理设置
        var result = transcriptionResponse.text
        if let settings = settings, settings.disableAutoCapitalization {
            result = result.lowercased()
        }
        
        TokLogger.log("OpenAI transcription completed: \(result.prefix(50))...")
        return result
    }
    
    func startStreamTranscription(/* ... */) async throws {
        // OpenAI 目前不支持流式转录
        throw TranscriptionError.streamingNotSupported
    }
    
    func stopStreamTranscription() async {
        // 无需实现
    }
    
    func prewarmModel(_ modelName: String, progressCallback: @escaping (Progress) -> Void) async throws {
        // OpenAI API 无需预热
        let progress = Progress(totalUnitCount: 100)
        progress.completedUnitCount = 100
        progressCallback(progress)
    }
    
    func cleanup() async {
        // 无需清理
    }
}
```

### 4. 统一的 TranscriptionClient 重构

```swift
/// 重构后的 TranscriptionClient，支持多引擎
@DependencyClient
struct TranscriptionClient {
    // 保持现有接口不变
    var transcribe: @Sendable (URL, String, DecodingOptions, HexSettings?, @escaping (Progress) -> Void) async throws -> String
    var downloadModel: @Sendable (String, @escaping (Progress) -> Void) async throws -> Void
    var deleteModel: @Sendable (String) async throws -> Void
    var isModelDownloaded: @Sendable (String) async -> Bool
    var getRecommendedModels: @Sendable () async throws -> ModelSupport
    var getAvailableModels: @Sendable () async throws -> [String]
    var prewarmModel: @Sendable (String, @escaping (Progress) -> Void) async throws -> Void
    var startStreamTranscription: @Sendable (String, DecodingOptions, HexSettings?, @escaping (StreamTranscriptionUpdate) -> Void) async throws -> Void
    var stopStreamTranscription: @Sendable () async -> Void
    var getTokenizer: @Sendable () async -> WhisperTokenizer?
    var cleanWhisperTokens: @Sendable (String) -> String
    
    // 新增接口
    var getAvailableProviders: @Sendable () async -> [TranscriptionProviderType]
    var getProviderModels: @Sendable (TranscriptionProviderType) async throws -> [TranscriptionModel]
    var switchProvider: @Sendable (TranscriptionProviderType) async throws -> Void
    var getCurrentProvider: @Sendable () async -> TranscriptionProviderType
    var testProviderConnection: @Sendable (TranscriptionProviderType, String?) async -> Bool
}

/// 多引擎支持的 TranscriptionClient 实现
actor TranscriptionClientLive {
    // 引擎管理
    private var engines: [TranscriptionProviderType: TranscriptionEngine] = [:]
    private var currentProvider: TranscriptionProviderType
    
    // 配置
    @Shared(.hexSettings) var hexSettings: HexSettings
    
    init() {
        // 初始化默认提供商
        self.currentProvider = hexSettings.transcriptionProviderType ?? .whisperKit
        
        // 初始化所有可用引擎
        Task {
            await initializeEngines()
        }
    }
    
    private func initializeEngines() async {
        // 本地 WhisperKit 引擎
        engines[.whisperKit] = LocalTranscriptionEngine()
        
        // 根据配置初始化远程引擎
        if !hexSettings.openaiAPIKey.isEmpty {
            engines[.openai] = OpenAITranscriptionEngine(apiKey: hexSettings.openaiAPIKey)
        }
        
        if !hexSettings.groqAPIKey.isEmpty {
            engines[.groq] = GroqTranscriptionEngine(apiKey: hexSettings.groqAPIKey)
        }
        
        // ... 其他引擎初始化
    }
    
    /// 智能选择最佳引擎
    private func selectOptimalEngine(for request: TranscriptionRequest) async -> TranscriptionEngine? {
        let availableEngines = engines.values.filter { engine in
            await engine.isAvailable()
        }
        
        // 根据用户偏好、网络状态、成本等因素选择
        if hexSettings.preferLocalTranscription {
            // 优先本地引擎
            if let localEngine = engines[.whisperKit], await localEngine.isAvailable() {
                return localEngine
            }
        }
        
        // 如果需要流式转录，过滤支持流式的引擎
        if request.requiresStreaming {
            return availableEngines.first { engine in
                engine.providerType.supportsStreaming
            }
        }
        
        // 根据成本和延迟选择
        return availableEngines.min { engine1, engine2 in
            let cost1 = await getCostEstimate(for: engine1, request: request)
            let cost2 = await getCostEstimate(for: engine2, request: request)
            return cost1 < cost2
        }
    }
    
    /// 转录实现（新版本，支持多引擎）
    func transcribe(
        url: URL,
        model: String,
        options: DecodingOptions,
        settings: HexSettings? = nil,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String {
        let request = TranscriptionRequest(
            audioURL: url,
            model: model,
            options: options,
            settings: settings,
            requiresStreaming: false
        )
        
        // 智能选择引擎
        guard let engine = await selectOptimalEngine(for: request) else {
            throw TranscriptionError.noAvailableEngine
        }
        
        TokLogger.log("Using \(engine.providerType.displayName) for transcription")
        
        // 执行转录
        do {
            return try await engine.transcribe(
                audioURL: url,
                model: model,
                options: options,
                settings: settings,
                progressCallback: progressCallback
            )
        } catch {
            // 如果失败，尝试降级到其他引擎
            return try await fallbackTranscription(request: request, failedEngine: engine, error: error, progressCallback: progressCallback)
        }
    }
    
    /// 降级转录策略
    private func fallbackTranscription(
        request: TranscriptionRequest,
        failedEngine: TranscriptionEngine,
        error: Error,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String {
        TokLogger.log("Transcription failed with \(failedEngine.providerType.displayName), attempting fallback")
        
        // 尝试其他可用引擎
        for (providerType, engine) in engines {
            if providerType == failedEngine.providerType { continue }
            if await !engine.isAvailable() { continue }
            
            do {
                TokLogger.log("Fallback to \(providerType.displayName)")
                return try await engine.transcribe(
                    audioURL: request.audioURL,
                    model: request.model,
                    options: request.options,
                    settings: request.settings,
                    progressCallback: progressCallback
                )
            } catch {
                TokLogger.log("Fallback failed with \(providerType.displayName): \(error)")
                continue
            }
        }
        
        // 所有引擎都失败，抛出原始错误
        throw error
    }
    
    // ... 其他方法实现
}

/// 转录请求结构
struct TranscriptionRequest {
    let audioURL: URL
    let model: String
    let options: DecodingOptions
    let settings: HexSettings?
    let requiresStreaming: Bool
}
```

### 5. 配置系统扩展

```swift
extension HexSettings {
    // 转录提供商相关配置
    var transcriptionProviderType: TranscriptionProviderType {
        get { TranscriptionProviderType(rawValue: _transcriptionProvider) ?? .whisperKit }
        set { _transcriptionProvider = newValue.rawValue }
    }
    
    private var _transcriptionProvider: String = TranscriptionProviderType.whisperKit.rawValue
    
    // API 密钥配置
    var openaiAPIKey: String = ""
    var groqAPIKey: String = ""
    var assemblyaiAPIKey: String = ""
    var deepgramAPIKey: String = ""
    
    // 智能选择配置
    var preferLocalTranscription: Bool = true
    var maxTranscriptionCostPerMinute: Double = 0.01  // 最大可接受成本
    var allowFallbackToRemote: Bool = true
    var fallbackOnNetworkError: Bool = true
    
    // 质量和性能偏好
    var transcriptionQualityPreference: TranscriptionQuality = .balanced
    var maxAcceptableLatency: TimeInterval = 30.0
}

enum TranscriptionQuality: String, Codable, CaseIterable {
    case fast = "fast"         // 优先速度
    case balanced = "balanced" // 平衡质量和速度
    case accurate = "accurate" // 优先准确度
    case cost = "cost"         // 优先成本
    
    var displayName: String {
        switch self {
        case .fast: return "快速"
        case .balanced: return "平衡"
        case .accurate: return "高精度"
        case .cost: return "低成本"
        }
    }
}
```

### 6. 错误处理和日志

```swift
/// 转录相关错误类型
enum TranscriptionError: Error, LocalizedError {
    case noAvailableEngine
    case engineNotSupported(TranscriptionProviderType)
    case apiKeyMissing(TranscriptionProviderType)
    case apiKeyInvalid(TranscriptionProviderType)
    case networkError(Error)
    case apiError(Int, String)
    case audioFormatNotSupported
    case audioTooLong(TimeInterval, TimeInterval)  // 实际时长, 最大时长
    case streamingNotSupported
    case quotaExceeded(TranscriptionProviderType)
    case invalidResponse
    case modelNotFound(String)
    
    var errorDescription: String? {
        switch self {
        case .noAvailableEngine:
            return "没有可用的转录引擎"
        case .engineNotSupported(let provider):
            return "\(provider.displayName) 引擎暂不支持"
        case .apiKeyMissing(let provider):
            return "\(provider.displayName) 需要 API 密钥"
        case .apiKeyInvalid(let provider):
            return "\(provider.displayName) API 密钥无效"
        case .networkError(let error):
            return "网络错误：\(error.localizedDescription)"
        case .apiError(let code, let message):
            return "API 错误 (\(code))：\(message)"
        case .audioFormatNotSupported:
            return "不支持的音频格式"
        case .audioTooLong(let actual, let max):
            return "音频时长超出限制（\(Int(actual))秒 > \(Int(max))秒）"
        case .streamingNotSupported:
            return "该引擎不支持流式转录"
        case .quotaExceeded(let provider):
            return "\(provider.displayName) 配额已用尽"
        case .invalidResponse:
            return "无效的 API 响应"
        case .modelNotFound(let model):
            return "找不到模型：\(model)"
        }
    }
}

/// 扩展 TokLogger 支持转录相关日志
extension TokLogger {
    static func logTranscription(_ message: String, provider: TranscriptionProviderType, level: TokLogLevel = .info) {
        log("[\(provider.rawValue.uppercased())] \(message)", level: level)
    }
    
    static func logTranscriptionError(_ error: Error, provider: TranscriptionProviderType) {
        logTranscription("Error: \(error.localizedDescription)", provider: provider, level: .error)
    }
}
```

## 用户界面设计

### 设置界面扩展

```swift
/// 转录设置视图
struct TranscriptionSettingsView: View {
    @Bindable var store: StoreOf<TranscriptionSettingsFeature>
    
    var body: some View {
        Form {
            Section("转录引擎") {
                Picker("默认引擎", selection: $store.settings.transcriptionProviderType) {
                    ForEach(TranscriptionProviderType.allCases, id: \.self) { provider in
                        Label {
                            VStack(alignment: .leading) {
                                Text(provider.displayName)
                                Text(provider.description)
                                    .font(.caption)
                                    .foregroundColor(.secondary)
                            }
                        } icon: {
                            Image(systemName: provider.iconName)
                                .foregroundColor(provider.iconColor)
                        }
                        .tag(provider)
                    }
                }
                .pickerStyle(.menu)
                
                Toggle("优先使用本地转录", isOn: $store.settings.preferLocalTranscription)
                Toggle("网络错误时自动降级", isOn: $store.settings.fallbackOnNetworkError)
            }
            
            Section("质量偏好") {
                Picker("转录质量", selection: $store.settings.transcriptionQualityPreference) {
                    ForEach(TranscriptionQuality.allCases, id: \.self) { quality in
                        Text(quality.displayName).tag(quality)
                    }
                }
                .pickerStyle(.segmented)
                
                HStack {
                    Text("最大可接受延迟")
                    Spacer()
                    Text("\(Int(store.settings.maxAcceptableLatency))秒")
                        .foregroundColor(.secondary)
                }
                Slider(value: $store.settings.maxAcceptableLatency, in: 5...60, step: 5)
                
                HStack {
                    Text("最大成本限制")
                    Spacer()
                    Text("$\(store.settings.maxTranscriptionCostPerMinute, specifier: "%.3f")/分钟")
                        .foregroundColor(.secondary)
                }
                Slider(value: $store.settings.maxTranscriptionCostPerMinute, in: 0.001...0.1, step: 0.001)
            }
            
            Section("API 配置") {
                ForEach(TranscriptionProviderType.allCases.filter(\.requiresAPIKey), id: \.self) { provider in
                    APIKeyConfigView(provider: provider, store: store)
                }
            }
            
            Section("引擎状态") {
                ForEach(store.availableProviders, id: \.self) { provider in
                    ProviderStatusView(provider: provider, store: store)
                }
            }
        }
        .task {
            await store.send(.refreshProviderStatus).finish()
        }
    }
}

/// API 密钥配置视图
struct APIKeyConfigView: View {
    let provider: TranscriptionProviderType
    @Bindable var store: StoreOf<TranscriptionSettingsFeature>
    @State private var showKey = false
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            HStack {
                Label(provider.displayName, systemImage: provider.iconName)
                Spacer()
                Button(action: { showKey.toggle() }) {
                    Image(systemName: showKey ? "eye.slash" : "eye")
                }
                .buttonStyle(.plain)
            }
            
            HStack {
                if showKey {
                    TextField("API 密钥", text: apiKeyBinding)
                        .textFieldStyle(.roundedBorder)
                } else {
                    SecureField("API 密钥", text: apiKeyBinding)
                        .textFieldStyle(.roundedBorder)
                }
                
                Button("测试") {
                    Task {
                        await store.send(.testAPIKey(provider)).finish()
                    }
                }
                .disabled(apiKeyBinding.wrappedValue.isEmpty)
            }
            
            if let status = store.apiKeyStatus[provider] {
                Label {
                    Text(status.message)
                        .font(.caption)
                } icon: {
                    Image(systemName: status.isValid ? "checkmark.circle.fill" : "xmark.circle.fill")
                        .foregroundColor(status.isValid ? .green : .red)
                }
            }
        }
    }
    
    private var apiKeyBinding: Binding<String> {
        switch provider {
        case .openai:
            return $store.settings.openaiAPIKey
        case .groq:
            return $store.settings.groqAPIKey
        case .assemblyai:
            return $store.settings.assemblyaiAPIKey
        case .deepgram:
            return $store.settings.deepgramAPIKey
        default:
            return .constant("")
        }
    }
}
```

## 实施计划

### 第一阶段：基础架构
1. **定义核心协议和类型**
   - `TranscriptionProviderType` 枚举
   - `TranscriptionEngine` 协议
   - `TranscriptionModel` 结构体
   - `TranscriptionError` 错误类型

2. **重构现有 TranscriptionClient**
   - 将现有实现封装为 `LocalTranscriptionEngine`
   - 创建新的多引擎支持的 `TranscriptionClientLive`
   - 保持现有接口兼容性

3. **扩展配置系统**
   - 扩展 `HexSettings` 支持新配置项
   - 实现配置迁移逻辑

### 第二阶段：OpenAI 集成
1. **实现 OpenAI 引擎**
   - `OpenAITranscriptionEngine` 类
   - API 调用逻辑和错误处理
   - 成本计算和限制检查

2. **集成测试**
   - 单元测试和集成测试
   - API 密钥验证和连接测试
   - 错误处理和降级测试

### 第三阶段：用户界面
1. **设置界面更新**
   - 转录引擎选择界面
   - API 密钥配置界面
   - 引擎状态监控界面

2. **用户体验优化**
   - 智能引擎推荐
   - 成本和性能显示
   - 错误提示和帮助

### 第四阶段：其他提供商
1. **Groq 引擎实现**
2. **AssemblyAI 引擎实现**
3. **Deepgram 引擎实现**

### 第五阶段：高级功能
1. **智能选择算法优化**
2. **性能监控和分析**
3. **批量处理和队列管理**
4. **成本控制和预算管理**

## 性能和安全考虑

### 性能优化
1. **连接池管理**：复用 HTTP 连接减少延迟
2. **请求缓存**：缓存相同音频的转录结果
3. **并发控制**：限制同时进行的 API 调用数量
4. **压缩优化**：音频文件压缩减少传输时间

### 安全措施
1. **API 密钥安全存储**：使用 Keychain 存储敏感信息
2. **传输加密**：所有 API 调用使用 HTTPS
3. **数据隐私**：提供本地优先选项保护隐私
4. **访问控制**：实现 API 使用限制和监控

### 可观测性
1. **详细日志记录**：记录所有关键操作和错误
2. **性能指标收集**：延迟、成功率、成本等指标
3. **用户反馈机制**：质量评价和问题报告
4. **健康检查**：定期检查各引擎状态

## 总结

本设计方案提供了一个可扩展、向后兼容的远程转录模型集成架构。通过借鉴现有 `AIEnhancementClient` 的成功模式，确保了架构的一致性和可维护性。核心特性包括：

- **无缝集成**：现有代码无需修改即可使用新功能
- **智能选择**：根据多种因素自动选择最佳转录引擎
- **优雅降级**：网络或 API 失败时自动回退到可用引擎
- **成本控制**：透明的成本显示和预算管理
- **隐私保护**：本地优先策略保护用户隐私

该架构为 Tok 应用提供了强大而灵活的转录能力，同时保持了简洁的用户体验和强大的技术基础。