# 远程转录模型集成设计 - 简化版本

## 概述

基于用户反馈，本文档提供了一个简化的远程转录集成方案。初期重点支持 OpenAI 的转录模型，用户可以直接选择具体的模型，而不是依赖自动分配。这个设计更加直观和可控。

## 设计原则

1. **用户主导选择**：用户直接选择要使用的具体模型，而不是系统自动分配
2. **渐进式实现**：初期只支持 OpenAI，后续可扩展其他提供商
3. **配置简化**：减少复杂的智能选择逻辑，专注核心功能
4. **向后兼容**：保持现有 WhisperKit 功能不变

## 支持的模型

### OpenAI 转录模型

基于 [OpenAI Speech-to-Text API](https://platform.openai.com/docs/guides/speech-to-text) 文档，初期支持：

1. **gpt-4o-mini-transcribe**
   - 成本更低的模型
   - 适合大量音频处理
   - 精度略低但速度更快

2. **gpt-4o-transcribe** 
   - 高精度模型
   - 更好的转录质量
   - 成本相对较高

### WhisperKit 本地模型（保持现有）

- openai_whisper-tiny
- openai_whisper-base  
- openai_whisper-large-v3-v20240930

## 技术实现

### 1. 模型类型定义

```swift
/// 转录模型类型，包含本地和远程模型
enum TranscriptionModelType: String, Codable, CaseIterable, Equatable {
    // 本地 WhisperKit 模型
    case whisperTiny = "openai_whisper-tiny"
    case whisperBase = "openai_whisper-base"
    case whisperLarge = "openai_whisper-large-v3-v20240930"
    
    // OpenAI 远程模型
    case openaiGpt4oMini = "gpt-4o-mini-transcribe"
    case openaiGpt4o = "gpt-4o-transcribe"
    
    var displayName: String {
        switch self {
        case .whisperTiny:
            return "Whisper Tiny (本地)"
        case .whisperBase:
            return "Whisper Base (本地)"
        case .whisperLarge:
            return "Whisper Large (本地)"
        case .openaiGpt4oMini:
            return "GPT-4o Mini Transcribe"
        case .openaiGpt4o:
            return "GPT-4o Transcribe"
        }
    }
    
    var description: String {
        switch self {
        case .whisperTiny:
            return "最小的本地模型，速度快但精度较低"
        case .whisperBase:
            return "平衡的本地模型，速度和精度适中"
        case .whisperLarge:
            return "最大的本地模型，精度高但速度较慢"
        case .openaiGpt4oMini:
            return "OpenAI 经济型转录模型，成本低廉"
        case .openaiGpt4o:
            return "OpenAI 高精度转录模型，质量最佳"
        }
    }
    
    var provider: TranscriptionProvider {
        switch self {
        case .whisperTiny, .whisperBase, .whisperLarge:
            return .whisperKit
        case .openaiGpt4oMini, .openaiGpt4o:
            return .openai
        }
    }
    
    var requiresAPIKey: Bool {
        return provider == .openai
    }
    
    var isLocal: Bool {
        return provider == .whisperKit
    }
    
    var estimatedCostPerMinute: Double {
        switch self {
        case .whisperTiny, .whisperBase, .whisperLarge:
            return 0.0  // 本地模型免费
        case .openaiGpt4oMini:
            return 0.001  // $0.001/分钟 (估算)
        case .openaiGpt4o:
            return 0.006  // $0.006/分钟 (估算)
        }
    }
}

/// 转录提供商
enum TranscriptionProvider: String, Codable {
    case whisperKit = "whisperkit"
    case openai = "openai"
}
```

### 2. 配置系统扩展

```swift
extension HexSettings {
    // 转录模型选择
    var selectedTranscriptionModel: TranscriptionModelType {
        get { 
            TranscriptionModelType(rawValue: _selectedTranscriptionModel) ?? .whisperLarge 
        }
        set { 
            _selectedTranscriptionModel = newValue.rawValue 
        }
    }
    
    private var _selectedTranscriptionModel: String = TranscriptionModelType.whisperLarge.rawValue
    
    // OpenAI API 配置
    var openaiAPIKey: String = ""
    var openaiAPIKeyLastTested: Date? = nil
    var openaiAPIKeyIsValid: Bool = false
    
    // 添加到 CodingKeys
    enum CodingKeys: String, CodingKey {
        // ... 现有的 keys
        case _selectedTranscriptionModel = "selectedTranscriptionModel"
        case openaiAPIKey
        case openaiAPIKeyLastTested  
        case openaiAPIKeyIsValid
    }
    
    // 更新 init 方法
    init(
        // ... 现有参数
        selectedTranscriptionModel: TranscriptionModelType = .whisperLarge,
        openaiAPIKey: String = "",
        openaiAPIKeyLastTested: Date? = nil,
        openaiAPIKeyIsValid: Bool = false
    ) {
        // ... 现有赋值
        self._selectedTranscriptionModel = selectedTranscriptionModel.rawValue
        self.openaiAPIKey = openaiAPIKey
        self.openaiAPIKeyLastTested = openaiAPIKeyLastTested
        self.openaiAPIKeyIsValid = openaiAPIKeyIsValid
    }
    
    // 更新自定义解码器
    init(from decoder: Decoder) throws {
        // ... 现有解码逻辑
        _selectedTranscriptionModel = try container.decodeIfPresent(String.self, forKey: ._selectedTranscriptionModel) ?? TranscriptionModelType.whisperLarge.rawValue
        openaiAPIKey = try container.decodeIfPresent(String.self, forKey: .openaiAPIKey) ?? ""
        openaiAPIKeyLastTested = try container.decodeIfPresent(Date.self, forKey: .openaiAPIKeyLastTested)
        openaiAPIKeyIsValid = try container.decodeIfPresent(Bool.self, forKey: .openaiAPIKeyIsValid) ?? false
    }
}
```

### 3. OpenAI 转录引擎实现

```swift
/// OpenAI 转录引擎，基于官方 API 文档实现
actor OpenAITranscriptionEngine {
    private let apiKey: String
    private let baseURL = "https://api.openai.com/v1"
    
    init(apiKey: String) {
        self.apiKey = apiKey
    }
    
    /// 测试 API 密钥有效性
    func testAPIKey() async -> Bool {
        guard !apiKey.isEmpty else { return false }
        
        do {
            var request = URLRequest(url: URL(string: "\(baseURL)/models")!)
            request.httpMethod = "GET"
            request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
            request.timeoutInterval = 10.0
            
            let (_, response) = try await URLSession.shared.data(for: request)
            
            if let httpResponse = response as? HTTPURLResponse {
                return httpResponse.statusCode == 200
            }
            return false
        } catch {
            print("[OpenAI] API key test failed: \(error)")
            return false
        }
    }
    
    /// 转录音频文件
    func transcribe(
        audioURL: URL,
        model: TranscriptionModelType,
        options: DecodingOptions,
        settings: HexSettings?,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String {
        guard model.provider == .openai else {
            throw TranscriptionError.invalidModel(model.rawValue)
        }
        
        let progress = Progress(totalUnitCount: 100)
        progressCallback(progress)
        
        // 检查文件大小限制 (OpenAI 限制 25MB)
        let fileSize = try getFileSize(url: audioURL)
        if fileSize > 25 * 1024 * 1024 {
            throw TranscriptionError.fileTooLarge(fileSize, 25 * 1024 * 1024)
        }
        
        progress.completedUnitCount = 10
        progressCallback(progress)
        
        // 准备请求
        var request = URLRequest(url: URL(string: "\(baseURL)/audio/transcriptions")!)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        
        // 创建 multipart 表单数据
        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")
        
        var body = Data()
        
        // 添加音频文件
        let audioData = try Data(contentsOf: audioURL)
        let filename = audioURL.lastPathComponent
        let mimeType = getMimeType(for: audioURL)
        
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"\(filename)\"\r\n".data(using: .utf8)!)
        body.append("Content-Type: \(mimeType)\r\n\r\n".data(using: .utf8)!)
        body.append(audioData)
        body.append("\r\n".data(using: .utf8)!)
        
        // 添加模型参数
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"model\"\r\n\r\n".data(using: .utf8)!)
        body.append(model.rawValue.data(using: .utf8)!)
        body.append("\r\n".data(using: .utf8)!)
        
        // 添加语言参数（如果指定）
        if let language = options.language, language != "auto" {
            body.append("--\(boundary)\r\n".data(using: .utf8)!)
            body.append("Content-Disposition: form-data; name=\"language\"\r\n\r\n".data(using: .utf8)!)
            body.append(language.data(using: .utf8)!)
            body.append("\r\n".data(using: .utf8)!)
        }
        
        // 添加响应格式
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"response_format\"\r\n\r\n".data(using: .utf8)!)
        body.append("json".data(using: .utf8)!)
        body.append("\r\n".data(using: .utf8)!)
        
        // 添加时间戳设置
        if !options.withoutTimestamps {
            body.append("--\(boundary)\r\n".data(using: .utf8)!)
            body.append("Content-Disposition: form-data; name=\"timestamp_granularities[]\"\r\n\r\n".data(using: .utf8)!)
            body.append("segment".data(using: .utf8)!)
            body.append("\r\n".data(using: .utf8)!)
        }
        
        body.append("--\(boundary)--\r\n".data(using: .utf8)!)
        
        request.httpBody = body
        request.timeoutInterval = 300  // 5分钟超时
        
        progress.completedUnitCount = 30
        progressCallback(progress)
        
        // 发送请求
        print("[OpenAI] Sending transcription request for model: \(model.displayName)")
        
        let (responseData, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw TranscriptionError.invalidResponse
        }
        
        progress.completedUnitCount = 80
        progressCallback(progress)
        
        if httpResponse.statusCode != 200 {
            let errorMessage = try parseErrorResponse(responseData)
            throw TranscriptionError.apiError(httpResponse.statusCode, errorMessage)
        }
        
        // 解析响应
        struct OpenAITranscriptionResponse: Codable {
            let text: String
        }
        
        let transcriptionResponse = try JSONDecoder().decode(OpenAITranscriptionResponse.self, from: responseData)
        
        progress.completedUnitCount = 100
        progressCallback(progress)
        
        // 应用设置（如禁用自动大写）
        var result = transcriptionResponse.text
        if let settings = settings, settings.disableAutoCapitalization {
            result = result.lowercased()
        }
        
        TokLogger.log("OpenAI transcription completed with \(model.displayName): \(result.prefix(50))...")
        return result
    }
    
    // MARK: - Helper Methods
    
    private func getFileSize(url: URL) throws -> Int {
        let attributes = try FileManager.default.attributesOfItem(atPath: url.path)
        return attributes[.size] as? Int ?? 0
    }
    
    private func getMimeType(for url: URL) -> String {
        let pathExtension = url.pathExtension.lowercased()
        switch pathExtension {
        case "mp3":
            return "audio/mpeg"
        case "wav":
            return "audio/wav"
        case "m4a":
            return "audio/m4a"
        case "flac":
            return "audio/flac"
        default:
            return "audio/wav"  // 默认为 wav
        }
    }
    
    private func parseErrorResponse(_ data: Data) throws -> String {
        struct ErrorResponse: Codable {
            struct Error: Codable {
                let message: String
                let type: String?
                let code: String?
            }
            let error: Error
        }
        
        do {
            let errorResponse = try JSONDecoder().decode(ErrorResponse.self, from: data)
            return errorResponse.error.message
        } catch {
            return String(data: data, encoding: .utf8) ?? "Unknown error"
        }
    }
}

/// 转录错误类型
enum TranscriptionError: Error, LocalizedError {
    case invalidModel(String)
    case fileTooLarge(Int, Int)  // 实际大小, 限制大小
    case apiKeyInvalid
    case apiError(Int, String)
    case invalidResponse
    case networkError(Error)
    
    var errorDescription: String? {
        switch self {
        case .invalidModel(let model):
            return "不支持的模型: \(model)"
        case .fileTooLarge(let actual, let limit):
            return "文件过大: \(actual) 字节，限制: \(limit) 字节"
        case .apiKeyInvalid:
            return "OpenAI API 密钥无效"
        case .apiError(let code, let message):
            return "API 错误 (\(code)): \(message)"
        case .invalidResponse:
            return "无效的 API 响应"
        case .networkError(let error):
            return "网络错误: \(error.localizedDescription)"
        }
    }
}
```

### 4. TranscriptionClient 集成

```swift
/// 扩展现有的 TranscriptionClientLive 支持 OpenAI
extension TranscriptionClientLive {
    
    /// 根据选择的模型执行转录
    func transcribe(
        url: URL,
        model: String,
        options: DecodingOptions,
        settings: HexSettings? = nil,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String {
        
        // 解析模型类型
        guard let modelType = TranscriptionModelType(rawValue: model) else {
            // 兼容原有模型字符串格式
            return try await transcribeWithWhisperKit(url: url, model: model, options: options, settings: settings, progressCallback: progressCallback)
        }
        
        switch modelType.provider {
        case .whisperKit:
            // 使用现有的 WhisperKit 实现
            return try await transcribeWithWhisperKit(url: url, model: modelType.rawValue, options: options, settings: settings, progressCallback: progressCallback)
            
        case .openai:
            // 使用 OpenAI API
            guard let settings = settings, !settings.openaiAPIKey.isEmpty else {
                throw TranscriptionError.apiKeyInvalid
            }
            
            let openaiEngine = OpenAITranscriptionEngine(apiKey: settings.openaiAPIKey)
            return try await openaiEngine.transcribe(
                audioURL: url,
                model: modelType,
                options: options,
                settings: settings,
                progressCallback: progressCallback
            )
        }
    }
    
    /// 使用 WhisperKit 进行转录（现有逻辑）
    private func transcribeWithWhisperKit(
        url: URL,
        model: String,
        options: DecodingOptions,
        settings: HexSettings?,
        progressCallback: @escaping (Progress) -> Void
    ) async throws -> String {
        // 保持现有的 WhisperKit 转录逻辑不变
        // ... (现有的实现代码)
        return ""  // 占位符
    }
    
    /// 获取可用模型列表（包含本地和远程）
    func getAvailableModels() async throws -> [String] {
        var allModels: [String] = []
        
        // 获取本地 WhisperKit 模型
        let localModels = try await getWhisperKitModels()
        allModels.append(contentsOf: localModels)
        
        // 添加 OpenAI 模型（如果配置了 API 密钥）
        if let settings = getSettings(), !settings.openaiAPIKey.isEmpty {
            allModels.append(TranscriptionModelType.openaiGpt4oMini.rawValue)
            allModels.append(TranscriptionModelType.openaiGpt4o.rawValue)
        }
        
        return allModels
    }
    
    /// 测试 OpenAI API 连接
    func testOpenAIConnection(apiKey: String) async -> Bool {
        let engine = OpenAITranscriptionEngine(apiKey: apiKey)
        return await engine.testAPIKey()
    }
    
    private func getSettings() -> HexSettings? {
        // 获取当前设置的辅助方法
        return getCachedSettings()
    }
    
    private func getWhisperKitModels() async throws -> [String] {
        // 调用现有的 WhisperKit 模型获取逻辑
        return []  // 占位符
    }
}
```

## 用户界面设计

### 1. 设置页面 - 转录模型选择

```swift
/// 转录模型设置视图
struct TranscriptionModelSettingsView: View {
    @Bindable var store: StoreOf<SettingsFeature>
    @State private var showingAPIKeyAlert = false
    @State private var testingAPIKey = false
    
    var body: some View {
        Form {
            Section {
                Picker("转录模型", selection: $store.settings.selectedTranscriptionModel) {
                    ForEach(TranscriptionModelType.allCases, id: \.self) { model in
                        ModelRow(model: model, settings: store.settings)
                            .tag(model)
                    }
                }
                .pickerStyle(.menu)
                .onChange(of: store.settings.selectedTranscriptionModel) { oldValue, newValue in
                    if newValue.requiresAPIKey && store.settings.openaiAPIKey.isEmpty {
                        showingAPIKeyAlert = true
                    }
                }
            } header: {
                Text("选择转录模型")
            } footer: {
                if let model = store.settings.selectedTranscriptionModel {
                    VStack(alignment: .leading, spacing: 4) {
                        Text(model.description)
                        
                        if model.estimatedCostPerMinute > 0 {
                            Text("预估成本: $\(model.estimatedCostPerMinute, specifier: "%.3f")/分钟")
                                .foregroundColor(.secondary)
                        }
                    }
                }
            }
            
            // OpenAI API 配置
            if store.settings.selectedTranscriptionModel.requiresAPIKey {
                Section {
                    APIKeyConfigurationView(store: store)
                } header: {
                    Text("OpenAI API 配置")
                } footer: {
                    Text("需要 OpenAI API 密钥才能使用远程转录模型。请访问 platform.openai.com 获取 API 密钥。")
                }
            }
        }
        .alert("需要 API 密钥", isPresented: $showingAPIKeyAlert) {
            Button("取消") {
                // 回退到本地模型
                store.send(.binding(.set(\.settings.selectedTranscriptionModel, .whisperLarge)))
            }
            Button("配置") {
                // 保持当前选择，用户需要配置 API 密钥
            }
        } message: {
            Text("所选模型需要 OpenAI API 密钥。请配置 API 密钥或选择本地模型。")
        }
    }
}

/// 模型行视图
struct ModelRow: View {
    let model: TranscriptionModelType
    let settings: HexSettings
    
    var body: some View {
        HStack {
            VStack(alignment: .leading, spacing: 2) {
                Text(model.displayName)
                    .fontWeight(.medium)
                
                HStack(spacing: 8) {
                    // 提供商标签
                    Label(model.isLocal ? "本地" : "远程", systemImage: model.isLocal ? "externaldrive" : "cloud")
                        .font(.caption)
                        .foregroundColor(model.isLocal ? .blue : .orange)
                    
                    // 成本标签
                    if model.estimatedCostPerMinute > 0 {
                        Label("$\(model.estimatedCostPerMinute, specifier: "%.3f")/分钟", systemImage: "dollarsign.circle")
                            .font(.caption)
                            .foregroundColor(.secondary)
                    } else {
                        Label("免费", systemImage: "checkmark.circle")
                            .font(.caption)
                            .foregroundColor(.green)
                    }
                }
            }
            
            Spacer()
            
            // 状态指示器
            if model.requiresAPIKey {
                if settings.openaiAPIKey.isEmpty {
                    Image(systemName: "exclamationmark.triangle.fill")
                        .foregroundColor(.orange)
                } else if settings.openaiAPIKeyIsValid {
                    Image(systemName: "checkmark.circle.fill")
                        .foregroundColor(.green)
                } else {
                    Image(systemName: "questionmark.circle.fill")
                        .foregroundColor(.secondary)
                }
            } else {
                Image(systemName: "checkmark.circle.fill")
                    .foregroundColor(.green)
            }
        }
    }
}

/// API 密钥配置视图
struct APIKeyConfigurationView: View {
    @Bindable var store: StoreOf<SettingsFeature>
    @State private var showAPIKey = false
    @State private var testingConnection = false
    
    var body: some View {
        VStack(spacing: 12) {
            HStack {
                if showAPIKey {
                    TextField("OpenAI API 密钥", text: $store.settings.openaiAPIKey)
                        .textFieldStyle(.roundedBorder)
                } else {
                    SecureField("OpenAI API 密钥", text: $store.settings.openaiAPIKey)
                        .textFieldStyle(.roundedBorder)
                }
                
                Button(action: { showAPIKey.toggle() }) {
                    Image(systemName: showAPIKey ? "eye.slash" : "eye")
                        .foregroundColor(.secondary)
                }
                .buttonStyle(.plain)
            }
            
            HStack {
                Button("测试连接") {
                    testConnection()
                }
                .disabled(store.settings.openaiAPIKey.isEmpty || testingConnection)
                
                if testingConnection {
                    ProgressView()
                        .scaleEffect(0.8)
                }
                
                Spacer()
                
                // 连接状态
                if let lastTested = store.settings.openaiAPIKeyLastTested {
                    HStack(spacing: 4) {
                        Image(systemName: store.settings.openaiAPIKeyIsValid ? "checkmark.circle.fill" : "xmark.circle.fill")
                            .foregroundColor(store.settings.openaiAPIKeyIsValid ? .green : .red)
                        
                        Text(store.settings.openaiAPIKeyIsValid ? "连接成功" : "连接失败")
                            .font(.caption)
                            .foregroundColor(.secondary)
                    }
                }
            }
        }
    }
    
    private func testConnection() {
        testingConnection = true
        Task {
            await store.send(.testOpenAIAPIKey).finish()
            testingConnection = false
        }
    }
}
```

### 2. Settings Feature 扩展

```swift
extension SettingsFeature {
    enum Action: BindableAction {
        // ... 现有 actions
        case testOpenAIAPIKey
        case openAIAPIKeyTestResult(Bool)
    }
    
    var body: some ReducerOf<Self> {
        BindingReducer()
        
        Reduce { state, action in
            switch action {
            // ... 现有 case 处理
            
            case .testOpenAIAPIKey:
                guard !state.settings.openaiAPIKey.isEmpty else {
                    return .none
                }
                
                return .run { [apiKey = state.settings.openaiAPIKey] send in
                    @Dependency(\.transcription) var transcriptionClient
                    let isValid = await transcriptionClient.testOpenAIConnection(apiKey)
                    await send(.openAIAPIKeyTestResult(isValid))
                }
                
            case .openAIAPIKeyTestResult(let isValid):
                state.settings.openaiAPIKeyIsValid = isValid
                state.settings.openaiAPIKeyLastTested = Date()
                
                if isValid {
                    TokLogger.log("OpenAI API key validation successful")
                } else {
                    TokLogger.log("OpenAI API key validation failed", level: .warn)
                }
                
                return .none
            }
        }
    }
}
```

## 实施步骤

### 第一阶段：基础架构（1-2天）
1. **定义模型类型**
   - 创建 `TranscriptionModelType` 枚举
   - 扩展 `HexSettings` 支持新配置
   - 定义错误类型

2. **OpenAI 引擎实现**
   - 实现 `OpenAITranscriptionEngine`
   - API 调用逻辑和错误处理
   - 文件上传和响应解析

### 第二阶段：集成现有系统（1天）
1. **扩展 TranscriptionClient**
   - 修改转录逻辑支持模型选择
   - 保持向后兼容性
   - 添加 API 密钥测试功能

### 第三阶段：用户界面（1-2天）
1. **设置页面更新**
   - 转录模型选择界面
   - API 密钥配置界面
   - 状态显示和测试功能

2. **Feature 集成**
   - 扩展 `SettingsFeature` 
   - 添加相关 Actions 和 Reducers

### 第四阶段：测试和优化（1天）
1. **功能测试**
   - OpenAI API 集成测试
   - 错误处理测试
   - 用户界面测试

2. **文档更新**
   - 用户使用指南
   - 开发者文档更新

## 成本和限制

### OpenAI API 限制
- **文件大小限制**: 25MB
- **支持格式**: mp3, mp4, mpeg, mpga, m4a, wav, webm
- **最大时长**: 约 25 分钟（取决于文件大小）

### 预估成本
- **gpt-4o-mini-transcribe**: ~$0.001/分钟
- **gpt-4o-transcribe**: ~$0.006/分钟

*注意：具体定价请参考 OpenAI 官方定价页面*

## 总结

这个简化版本的设计专注于：

1. **用户友好**: 直接选择具体模型，而不是复杂的自动分配
2. **渐进实现**: 先支持 OpenAI，为后续扩展打好基础
3. **配置简单**: 明确的 API 密钥配置和状态显示
4. **向后兼容**: 保持现有 WhisperKit 功能完全不变

该设计提供了一个清晰、可控的远程转录集成方案，用户可以根据自己的需求在本地和远程模型之间做出明智的选择。